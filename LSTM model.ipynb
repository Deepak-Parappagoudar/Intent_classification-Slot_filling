{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import required libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import  Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string,re\n",
    "string.punctuation\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Dense, LSTM, Embedding, Bidirectional\n",
    "from keras.layers import Dropout, Activation, GlobalMaxPooling1D  \n",
    "from keras import initializers, regularizers, optimizers, constraints, layers\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras_preprocessing.sequence import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdVkqlWrrwXn"
   },
   "source": [
    "**Import the previously generated dataset**\n",
    "\n",
    "How to: change path to where your csv file was saved "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uCT81PlfjP0t"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "df=pd.read_csv('final_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYTGT0QWsefl"
   },
   "source": [
    "Remove punctuations, URLs and articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "00XtcyOt74E1"
   },
   "outputs": [],
   "source": [
    "articles=['a','an','the']\n",
    "def clean_text(text):\n",
    "    \n",
    "  clean=\"\".join([i for i in text if i not in string.punctuation])\n",
    "  clean=re.sub(r\"http\\S+\", \"\", clean)\n",
    "  text_clean=[word.lower() for word in clean.split() if word not in articles]\n",
    "  clean=\" \".join(text_clean)\n",
    "  return clean\n",
    "\n",
    "df['text']=df['text'].apply(lambda x: clean_text(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3tzbNSJlsykg"
   },
   "source": [
    "We need this(num_words) to insert it in embedding layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y0HU-wZj74HM"
   },
   "outputs": [],
   "source": [
    "def counter_words(text):\n",
    "  count=Counter()\n",
    "  for i in text.values:\n",
    "    for word in i.split():\n",
    "      count[word]+=1\n",
    "  return count\n",
    "\n",
    "text=df.text\n",
    "counter=counter_words(text)\n",
    "num_words=len(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5EcnZeaRs-aG"
   },
   "source": [
    "Create arrays X: feature and y:labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bZGs7HZ074Kp"
   },
   "outputs": [],
   "source": [
    "X=df['text']\n",
    "\n",
    "y = pd.get_dummies(df['intent']).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xer_EkmetcqB"
   },
   "source": [
    "**Split data into training and testing (validation) data**\n",
    "\n",
    "In this case, we have choosen training data and test data to be 70 percent and 30 percent of the dataset respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "60EcM03N74Ow"
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aATPKeWtuI8C"
   },
   "source": [
    "Convert words in the feature to tokens.\n",
    "\n",
    "Convert each command (sentence) of feature to a sequence of tokens.\n",
    "\n",
    "Padding is done to make the length of each command sequence equal(50 in our case) as this is a requirement to input data into the neural networks. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yMc091PR74RC"
   },
   "outputs": [],
   "source": [
    "tokenizer=text.Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "train_sequence=tokenizer.texts_to_sequences(X_train)\n",
    "train_paded= pad_sequences(train_sequence, maxlen=50)\n",
    "\n",
    "test_sequence=tokenizer.texts_to_sequences(X_test)\n",
    "test_paded= pad_sequences(test_sequence, maxlen=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the LSTM model with appropiate input, hidden and output layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TCEASxtU74YT"
   },
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "embedding_size=128\n",
    "\n",
    "model.add(Embedding(num_words, embedding_size, input_length=50))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(6, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bjpl0xyY74ah"
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=3e-4)\n",
    "model.compile(optimizer=opt,loss = 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit training data and test the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TtPyqTAU74d3",
    "outputId": "0f717fa0-4c37-4925-a834-c43c82acc0d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "14755/14755 [==============================] - 5441s 369ms/step - loss: 0.0675 - accuracy: 0.9776 - val_loss: 0.0111 - val_accuracy: 0.9969\n",
      "Epoch 2/2\n",
      "14755/14755 [==============================] - 5462s 370ms/step - loss: 0.0098 - accuracy: 0.9974 - val_loss: 0.0071 - val_accuracy: 0.9979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f75f5436fd0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_paded, y_train , epochs=5, batch_size=128, validation_data= (test_paded,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model and tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "IMgp4-qRv7PC",
    "outputId": "40ba5936-6bb2-42e7-d1c6-b99baf0d2a67"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/drive/MyDrive/intent_LSTM.h5'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save('intent_LSTM.h5')\n",
    "\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model and tokenizer.\n",
    "After saving the model, it can be directly loaded (no need to run the corpus and train the model every time) to make predications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "huNNhSRowHeH"
   },
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model('intent_LSTM.h5')\n",
    "\n",
    "with open('/content/drive/MyDrive/tokenizer.pickle', 'rb') as handle:\n",
    "    loaded_tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict new text by taking input from the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cbGiszgAwHaq",
    "outputId": "445ada16-7696-472d-d70b-d65f8f98afaf",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "classes=['action', 'query', 'monitor', 'query+action', 'triger+action',\n",
    "       'trigger+query']\n",
    "\n",
    "test= input()\n",
    "seq= loaded_tokenizer.texts_to_sequences([test])\n",
    "padded = pad_sequences(seq, maxlen=50)\n",
    "pred = loaded_model.predict(padded)\n",
    "pred=np.argmax(pred)\n",
    "print(classes[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V7J8ysp0wHS2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HiWi.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
