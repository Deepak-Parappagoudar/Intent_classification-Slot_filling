{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string,re\n",
    "string.punctuation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import  Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the prepared dataset\n",
    "How to: specify the location of the saved dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o5VlLZLSS9ss"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove punctuations, URLs and articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MuSR5g-MT3mQ"
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "  articles=['a','an','the']\n",
    "\n",
    "  pre=\"\".join([i for i in text if i not in string.punctuation])\n",
    "\n",
    "  pre=re.sub(r\"http\\S+\", \"\", pre) \n",
    "\n",
    "  pre=[word.lower() for word in pre.split() if word not in articles]\n",
    "    \n",
    "  return \" \".join(pre)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create arrays X: feature and y:labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gp4K0fN_T4-F"
   },
   "outputs": [],
   "source": [
    "X=df['text']\n",
    "y=df['intent']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQUMnFoIX-On"
   },
   "source": [
    "Split data into training and testing (validation) data\n",
    "\n",
    "In this case, we have choosen training data and test data to be 70 percent and 30 percent of the dataset respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a0STTCmfT47Q"
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enocde the intent labels as numericals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Wkibx3OYWwC"
   },
   "outputs": [],
   "source": [
    "Encoder = LabelEncoder()\n",
    "y_train = Encoder.fit_transform(y_train)\n",
    "y_test = Encoder.fit_transform(y_test)\n",
    "y_train = Encoder.fit_transform(y_train)\n",
    "y_test = Encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Tf-Idf(Term Frequency â€” Inverse Document Frequency) to transform text to feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vz3N2Oe0UNVk"
   },
   "outputs": [],
   "source": [
    "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "Tfidf_vect.fit(df['text'])\n",
    "X_train = Tfidf_vect.transform(X_train)\n",
    "X_test = Tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the Naive-Bayes classifier and test the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I4pL3_LXUNPT",
    "outputId": "e4ec073e-702f-436a-d079-e62e670136c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.70841659492139\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(X_train,y_train)\n",
    "\n",
    "predictions_NB = Naive.predict(X_test)\n",
    "\n",
    "acc=accuracy_score(predictions_NB, y_test)*100\n",
    "print(acc)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "HiWi-SVM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
